---
title: "smart scheduling"
author: "Jakob Richter"
date: "18.11.2015"
output: html_document
---

```{r batchJobs}
library(BatchExperiments)
library(data.table)
reg = loadRegistry("~/lido_nobackup/rambo")
reducer = function(job, res){
  res.dt = cbind(
    prob = job$prob.id,
    algo = job$algo.id,
    repl = job$repl,
    seed = job$seed,
    setNames(job$prob.pars, paste0("probpar.", names(job$prob.pars))),
    setNames(job$algo.pars, paste0("algopar.", names(job$algo.pars))),
    t(setNames(res$performance, paste0("test.", names(res$performance)))),
    tune.y = res$model$learner.model$opt.result$mbo.result$y,
    do.call(cbind, setNames(res$model$learner.model$opt.result$mbo.result$x, paste0("x.", names(res$model$learner.model$opt.result$mbo.result$x)))),
    as.data.frame(res$model$learner.model$opt.result$mbo.result$opt.path))
}
res.list = reduceResultsList(reg, fun = reducer)
res.dt = rbindlist(res.list, fill = TRUE)
head(res.dt)
```

```{r initial design the same?}
length(unique(res.dt[dob == 0 & probpar.fold == 1 & selected.learner == "classif.svm.radial", .SD[1,] ,by = algopar.config.name]$classif.svm.radial.gamma)) == 1
```

```{r randomSearch normalisieren}
#TODO?
#res.rs = res.dt[algopar.config.name == "rs", ]
```

```{r laufzeiten einbauen}
res.dt[, ':='(exec.timestamp.dob = as.integer(exec.timestamp) - min(exec.timestamp), cummin.y = cummin(y)), by = .(prob, algo, repl, probpar.fold, algopar.config.name, dob)]
#wie lange braucht ein dob-schritt und welches ymin erreicht er
res.dt.dobs = res.dt[, list(dob.ymin = min(y), dob.exec.time = max(exec.timestamp + as.integer(exec.time)) - min(exec.timestamp)), by = .(prob, algo, repl, probpar.fold, algopar.config.name, dob)]
#summiere dob schritte auf
res.dt.dobs[, ':='(dob.endtime = cumsum(dob.exec.time), dob.cummin.y = cummin(dob.ymin)), by = .(algo, prob, repl, probpar.fold, algopar.config.name)]
res.dt = res.dt[res.dt.dobs, , on = c("prob", "algo", "repl", "probpar.fold", "algopar.config.name", "dob")]
#find out where a job was actaully executed
getExecOn = function(exec.times, exec.endtimes, ncpus) {
  used.time = numeric(ncpus)
  exec.on = numeric(length(exec.times))
  for (i in seq_along(exec.times)) {
    exec.on[i] = which.min(used.time) 
    used.time[exec.on[i]] = exec.endtimes[i]
  }
  exec.on
}
res.dt[, ':='(exec.on = getExecOn(exec.timestamp.dob, exec.timestamp.dob+exec.time, max(res.dt$scheduled.on, na.rm = TRUE))), by = .(prob, algo, probpar.fold, algopar.config.name, dob)]

#end results
end.res = res.dt[, .SD[.N,], by = .(prob, algo, repl, probpar.fold, algopar.config.name)]
end.res.fold = end.res[, lapply(.SD[, list(cummin.y, dob.endtime, test.mmce)], mean), by = .(prob, algo, repl, algopar.config.name)]
```

Analyze runtimes
```{r}
g = ggplot(res.dt, aes(x = dob , y = y, color = selected.learner))
g = g + geom_point()
g = g + geom_hline(data = end.res, mapping = aes(yintercept = test.mmce, color = x.selected.learner), alpha = 0.5)
g = g + geom_text(data = end.res, mapping = aes(y = test.mmce, label = algopar.config.name), size = 4, color = "black")
g + facet_grid(prob+probpar.fold~algopar.config.name)

g = ggplot(res.dt, aes(x = exec.time, y = y, color = selected.learner, shape = dob == 0))
g + geom_point(alpha = 0.5) + facet_wrap(~prob, scales = "free") + scale_shape_manual(values = c(16,1)) + scale_x_log10()
```

Performance, relativ naiv einfach am ende
```{r}
g = ggplot(end.res, aes(x = algopar.config.name, y = cummin.y, fill = algopar.config.name))
g + geom_boxplot() + facet_wrap(~prob, scales = "free")

g = ggplot(end.res, aes(x = algopar.config.name, y = test.mmce, fill = algopar.config.name))
g + geom_boxplot() + facet_wrap(~prob, scales = "free")
```

Zeitverlauf
```{r}
res.dt
g = ggplot(res.dt[dob > 0,], aes(y = dob.cummin.y, x = dob.endtime, color = algopar.config.name))
g + geom_line() + facet_wrap(prob~probpar.fold, scales = "free")
```

Scheduling Analyse
```{r}
#how it was planned
g = ggplot(res.dt[probpar.fold == 1], aes(y = exec.on, x = dob.endtime - dob.exec.time + exec.timestamp.dob, color = selected.learner))
g = g + geom_segment(aes(yend = exec.on, xend = dob.endtime - dob.exec.time + exec.timestamp.dob + exec.time), lwd = 2, alpha = 0.8)
g = g + geom_vline(aes(xintercept = dob.endtime), alpha = 0.2)
g + facet_grid(algopar.config.name~prob, scales = "free") + theme_bw()
```

Paretofront
```{r}
g = ggplot(end.res, aes(y = dob.endtime, x = test.mmce, color = algopar.config.name))
g = g + geom_point(size = 5) + facet_wrap(~prob, scales = "free") + stat_summary(fun.y = mean, fun.x = mean, geom="point")
g
```

```{r}
res.dt[algopar.config.name == "r.s.lcb" & probpar.fold == 6]
```
